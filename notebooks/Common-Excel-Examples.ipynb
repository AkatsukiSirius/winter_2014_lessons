{
 "metadata": {
  "name": "",
  "signature": "sha256:e7ec4057eacf8110673e5c770d2e5ecd46bfe57118a0c34aa4033c82ae645a72"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Part I"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Common Excel Tasks Demonstrated in Pandas - Chris Moffitt](http://pbpython.com/excel-pandas-comp.html)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Adding a Sum to a Row\n",
      "The first task I\u2019ll cover is summing some columns to add a total column.\n",
      "\n",
      "We will start by importing our excel data into a pandas dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "df = pd.read_excel(\"../data/excel-comp-data.xlsx\")\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"total\"] = df[\"Jan\"] + df[\"Feb\"] + df[\"Mar\"]\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let\u2019s get some totals and other values for each month.\n",
      "\n",
      "\n",
      "Performing column level analysis is easy in pandas. Here are a couple of examples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"Jan\"].sum(), df[\"Jan\"].mean(),df[\"Jan\"].min(),df[\"Jan\"].max()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we want to add a total by month and grand total. This is where pandas and Excel diverge a little. It is very simple to add totals in cells in Excel for each month. Because pandas need to maintain the integrity of the entire DataFrame, there are a couple more steps.\n",
      "\n",
      "First, create a sum for the month and total columns."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_row=df[[\"Jan\",\"Feb\",\"Mar\",\"total\"]].sum()\n",
      "sum_row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is fairly intuitive however, if you want to add totals as a row, you need to do some minor manipulations.\n",
      "\n",
      "We need to transpose the data and convert the Series to a DataFrame so that it is easier to concat onto our existing data. The T function allows us to switch the data from being row-based to column-based."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sum=pd.DataFrame(data=sum_row).T\n",
      "df_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The final thing we need to do before adding the totals back is to add the missing columns. We use reindex to do this for us. The trick is to add all of our columns and then allow pandas to fill in the values that are missing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sum=df_sum.reindex(columns=df.columns)\n",
      "df_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have a nicely formatted DataFrame, we can add it to our existing one using append."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_final=df.append(df_sum,ignore_index=True)\n",
      "df_final.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Additional Data Transforms\n",
      "For another example, let\u2019s try to add a state abbreviation to the data set.\n",
      "\n",
      "From an Excel perspective the easiest way is probably to add a new column, do a vlookup on the state name and fill in the abbreviation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You\u2019ll notice that after performing the vlookup, there are some values that are not coming through correctly. That\u2019s because we misspelled some of the states. Handling this in Excel would be really challenging (on big data sets).\n",
      "\n",
      "Fortunately with pandas we have the full power of the python ecosystem at our disposal. In thinking about how to solve this type of messy data problem, I thought about trying to do some fuzzy text matching to determine the correct value.\n",
      "\n",
      "Fortunately someone else has done a lot of work in this are. The [fuzzy wuzzy](http://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/) library has some pretty useful functions for this type of situation. Make sure to get it and install it first.\n",
      "\n",
      "The other piece of code we need is a state name to abbreviation mapping. Instead of trying to type it myself, a little googling found this [code](http://www.cmmichael.com/blog/2006/12/29/state-code-mappings-for-python).\n",
      "\n",
      "Get started by importing the appropriate fuzzywuzzy functions and define our state map dictionary."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from fuzzywuzzy import fuzz\n",
      "from fuzzywuzzy import process\n",
      "state_to_code = {\"VERMONT\": \"VT\", \"GEORGIA\": \"GA\", \"IOWA\": \"IA\", \"Armed Forces Pacific\": \"AP\", \"GUAM\": \"GU\",\n",
      "                 \"KANSAS\": \"KS\", \"FLORIDA\": \"FL\", \"AMERICAN SAMOA\": \"AS\", \"NORTH CAROLINA\": \"NC\", \"HAWAII\": \"HI\",\n",
      "                 \"NEW YORK\": \"NY\", \"CALIFORNIA\": \"CA\", \"ALABAMA\": \"AL\", \"IDAHO\": \"ID\", \"FEDERATED STATES OF MICRONESIA\": \"FM\",\n",
      "                 \"Armed Forces Americas\": \"AA\", \"DELAWARE\": \"DE\", \"ALASKA\": \"AK\", \"ILLINOIS\": \"IL\",\n",
      "                 \"Armed Forces Africa\": \"AE\", \"SOUTH DAKOTA\": \"SD\", \"CONNECTICUT\": \"CT\", \"MONTANA\": \"MT\", \"MASSACHUSETTS\": \"MA\",\n",
      "                 \"PUERTO RICO\": \"PR\", \"Armed Forces Canada\": \"AE\", \"NEW HAMPSHIRE\": \"NH\", \"MARYLAND\": \"MD\", \"NEW MEXICO\": \"NM\",\n",
      "                 \"MISSISSIPPI\": \"MS\", \"TENNESSEE\": \"TN\", \"PALAU\": \"PW\", \"COLORADO\": \"CO\", \"Armed Forces Middle East\": \"AE\",\n",
      "                 \"NEW JERSEY\": \"NJ\", \"UTAH\": \"UT\", \"MICHIGAN\": \"MI\", \"WEST VIRGINIA\": \"WV\", \"WASHINGTON\": \"WA\",\n",
      "                 \"MINNESOTA\": \"MN\", \"OREGON\": \"OR\", \"VIRGINIA\": \"VA\", \"VIRGIN ISLANDS\": \"VI\", \"MARSHALL ISLANDS\": \"MH\",\n",
      "                 \"WYOMING\": \"WY\", \"OHIO\": \"OH\", \"SOUTH CAROLINA\": \"SC\", \"INDIANA\": \"IN\", \"NEVADA\": \"NV\", \"LOUISIANA\": \"LA\",\n",
      "                 \"NORTHERN MARIANA ISLANDS\": \"MP\", \"NEBRASKA\": \"NE\", \"ARIZONA\": \"AZ\", \"WISCONSIN\": \"WI\", \"NORTH DAKOTA\": \"ND\",\n",
      "                 \"Armed Forces Europe\": \"AE\", \"PENNSYLVANIA\": \"PA\", \"OKLAHOMA\": \"OK\", \"KENTUCKY\": \"KY\", \"RHODE ISLAND\": \"RI\",\n",
      "                 \"DISTRICT OF COLUMBIA\": \"DC\", \"ARKANSAS\": \"AR\", \"MISSOURI\": \"MO\", \"TEXAS\": \"TX\", \"MAINE\": \"ME\"}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here are some example of how the fuzzy text matching function works."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process.extractOne(\"Minnesotta\",choices=state_to_code.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "process.extractOne(\"AlaBAMMazzz\",choices=state_to_code.keys(),score_cutoff=80)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know how this works, we create our function to take the state column and convert it to a valid abbreviation. We use the 80 score_cutoff for this data. You can play with it to see what number works for your data. You\u2019ll notice that we either return a valid abbreviation or an np.nan so that we have some valid values in the field."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_state(row):\n",
      "    abbrev = process.extractOne(row[\"state\"],choices=state_to_code.keys(),score_cutoff=80)\n",
      "    if abbrev:\n",
      "        return state_to_code[abbrev[0]]\n",
      "    return np.nan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Add the column in the location we want and fill it with NaN values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_final.insert(6, \"abbrev\", np.nan)\n",
      "df_final.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We use apply to add the abbreviations into the approriate column."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_final['abbrev'] = df_final.apply(convert_state, axis=1)\n",
      "df_final.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I think this is pretty cool. We have developed a very simple process to intelligently clean up this data. Obviously when you only have 15 or so rows, this is not a big deal. However, what if you had 15,000? You would have to do something manual in Excel to clean this up."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Subtotals\n",
      "For the final section of this article, let\u2019s get some subtotals by state.\n",
      "\n",
      "Creating a subtotal in pandas, is accomplished using groupby"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sub=df_final[[\"abbrev\",\"Jan\",\"Feb\",\"Mar\",\"total\"]].groupby('abbrev').sum()\n",
      "df_sub"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we want to format the data as currency by using applymap to all the values in the data frame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def money(x):\n",
      "    return \"${:,.0f}\".format(x)\n",
      "\n",
      "formatted_df = df_sub.applymap(money)\n",
      "formatted_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The formatting looks good, now we can get the totals like we did earlier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum_row=df_sub[[\"Jan\",\"Feb\",\"Mar\",\"total\"]].sum()\n",
      "sum_row"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Convert the values to columns and format it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_sub_sum=pd.DataFrame(data=sum_row).T\n",
      "df_sub_sum=df_sub_sum.applymap(money)\n",
      "df_sub_sum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, add the total value to the DataFrame."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_table = formatted_df.append(df_sub_sum)\n",
      "final_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You\u2019ll notice that the index is \u20180\u2019 for the total line. We want to change that using rename."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_table = final_table.rename(index={0:\"Total\"})\n",
      "final_table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Part II"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Common Excel Tasks Demonstrated in Pandas - Part 2](http://pbpython.com/excel-pandas-comp-2.html)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting Set Up"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import the pandas and numpy modules."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load in the Excel data that represents a year's worth of sales."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_excel(\"../data/sample-salesv3.xlsx\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Take a quick look at the data types to make sure everything came through as expected."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll notice that our date column is showing up as a generic `object`. We are going to convert it to datetime object to make some selections a little easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df['date'] = pd.to_datetime(df['date'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.dtypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The date is now a datetime object which will be useful in future steps."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Filtering the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similar to the autofilter function in Excel, you can use pandas to filter and select certain subsets of data.\n",
      "\n",
      "For instance, if we want to just see a specific account number, we can easily do that with pandas.\n",
      "\n",
      "Note, I am going to use the `head` function to show the top results. This is purely for the purposes of keeping the article shorter."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df[\"account number\"]==307599].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You could also do the filtering based on numeric values."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df[\"quantity\"] > 22].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we want to do more complex filtering, we can use `map` to filter. In this example, let's look for items with sku's that start with B1."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df[\"sku\"].map(lambda x: x.startswith('B1'))].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's easy to chain two statements together using the &."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df[\"sku\"].map(lambda x: x.startswith('B1')) & (df[\"quantity\"] > 22)].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another useful function that pandas supports is called `isin`. It allows us to define a list of values we want to look for.\n",
      "\n",
      "In this case, we look for all records that include two specific account numbers."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df[\"account number\"].isin([714466,218895])].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas supports another function called `query` which allows you to efficiently select subsets of data. It does require the installation of [numexpr](https://github.com/pydata/numexpr) so make sure you have it installed before trying this step.\n",
      "\n",
      "If you would like to get a list of customers by name, you can do that with a query, similar to the python syntax shown above."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.query('name == [\"Kulas Inc\",\"Barton LLC\"]').head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The query function allows you do more than just this simple example but for the purposes of this discussion, I'm showing it so you are aware that it is out there for you."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Working with Dates"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using pandas, you can do complex filtering on dates. Before doing anything with dates, I encourage you to sort by the date column to make sure the results return what you are expecting."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df.sort('date')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The python filtering syntax shown before works with dates."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['date'] >='20140905'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the really nice features of pandas is that it understands dates so will allow us to do partial filtering. If we want to only look for data more recent than a specific month, we can do so."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['date'] >='2014-03'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, you can chain the criteria."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[(df['date'] >='20140701') & (df['date'] <= '20140715')].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Because pandas understands date columns, you can express the date value in multiple formats and it will give you the results you expect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['date'] >= 'Oct-2014'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['date'] >= '10-10-2014'].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When working with time series data, if we convert the data to use the date as at the index, we can do some more filtering.\n",
      "\n",
      "Set the new index using `set_index`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2 = df.set_index(['date'])\n",
      "df2.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can slice the data to get a range."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2[\"20140101\":\"20140201\"].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once again, we can use various date representations to remove any ambiguity around date naming conventions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2[\"2014-Jan-1\":\"2014-Feb-1\"].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2[\"2014-Jan-1\":\"2014-Feb-1\"].tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2[\"2014\"].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df2[\"2014-Dec\"].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Additional String Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas has support for vectorized string functions as well. If we want to identify all the skus that contain a certain value, we can use `str.contains`. In this case, we know that the sku is always represented in the same way, so B1 only shows up in the front of the sku."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[df['sku'].str.contains('B1')].head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can string queries together and use sort to control how the data is ordered."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A common need I have in Excel is to understand all the unique items in a column. For instance, maybe I only want to know when customers purchased in this time period. The unique function makes this trivial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[(df['sku'].str.contains('B1-531')) & (df['quantity']>40)].sort(columns=['quantity','name'],ascending=[0,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Bonus Task"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I frequently find myself trying to get a list of unique items in a long list within Excel. It is a multi-step process to do this in Excel but is fairly simple in pandas. We just use the `unique` function on a column to get the list."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df[\"name\"].unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we wanted to include the account number, we could use `drop_duplicates`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.drop_duplicates(subset=[\"account number\",\"name\"]).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are obviously pulling in more data than we need and getting some non-useful information, so select only the first and second columns using `ix`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.drop_duplicates(subset=[\"account number\",\"name\"]).ix[:,[0,1]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I hope you found this useful. I encourage you to try and apply these ideas to some of your own repetitive Excel tasks and streamline your work flow."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}